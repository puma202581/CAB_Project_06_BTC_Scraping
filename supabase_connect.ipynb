{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "dbconn = os.getenv(\"DBCONN\")\n",
    "dbconn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d572390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %pip install psycopg2\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "# establish database connection using connection string from .env\n",
    "conn = psycopg2.connect(dbconn)\n",
    "\n",
    "# check if the connection is open\n",
    "# if conn.closed:\n",
    "#     raise Exception(\"Connection to the database failed\")\n",
    "# # print connection status\n",
    "# print(\"Connection to the database is open\")\n",
    "# # print connection info\n",
    "# print(conn.get_dsn_parameters())\n",
    "# # print server version\n",
    "# print(\"Server version:\", conn.server_version)\n",
    "\n",
    "\n",
    "# create a cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8de646",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS daily_prices (\n",
    "            Date TIMESTAMP,\n",
    "            Open FLOAT,\n",
    "            High FLOAT,\n",
    "            Low FLOAT,\n",
    "            Close FLOAT,\n",
    "            Volume INTEGER,\n",
    "            PRIMARY KEY(Date)\n",
    "        )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the cursor and sever connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01669019",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"APLHAVANTAGEAPIKEY\")\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883885f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey=\" + api_key\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "data = response.json()\n",
    "\n",
    "# Display the latest 5 days of daily prices in a readable format\n",
    "time_series = data.get(\"Time Series (Daily)\", {})\n",
    "for date in sorted(time_series.keys(), reverse=True)[:5]:\n",
    "    print(f\"Date: {date}\")\n",
    "    for key, value in time_series[date].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def insert_data_pg(date, open_price, high_price, low_price, close_price, volume):\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        INSERT INTO daily_prices (Date, Open, High, Low, Close, Volume)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (Date) DO UPDATE SET\n",
    "            Open = EXCLUDED.Open,\n",
    "            High = EXCLUDED.High,\n",
    "            Low = EXCLUDED.Low,\n",
    "            Close = EXCLUDED.Close,\n",
    "            Volume = EXCLUDED.Volume\n",
    "    ''', (date, open_price, high_price, low_price, close_price, volume))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Insert the data into the database\n",
    "for date, prices in time_series.items():\n",
    "    insert_data_pg(\n",
    "        date,\n",
    "        float(prices[\"1. open\"]),\n",
    "        float(prices[\"2. high\"]),\n",
    "        float(prices[\"3. low\"]),\n",
    "        float(prices[\"4. close\"]),\n",
    "        int(prices[\"5. volume\"])\n",
    "    )\n",
    "\n",
    "def query_data_pg():\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT * FROM daily_prices ORDER BY Date DESC LIMIT 5')\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "# Print the last 5 entries from the database\n",
    "last_entries = query_data_pg()\n",
    "for entry in last_entries:\n",
    "    print(f\"Date: {entry[0]}, Open: {entry[1]}, High: {entry[2]}, Low: {entry[3]}, Close: {entry[4]}, Volume: {entry[5]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://u.today/search/node?keys=bitcoin\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract article titles, dates, authors, and links\n",
    "main_block = soup.find('main', class_='main-block')\n",
    "articles = main_block.find_all('div', class_='news__item') if main_block else []\n",
    "data = []\n",
    "seen = set()\n",
    "for article in articles:\n",
    "    # Title\n",
    "    title_tag = article.find('div', class_='news__item-title')\n",
    "    title = title_tag.get_text(strip=True) if title_tag else 'No Title'\n",
    "    # Date\n",
    "    date_tag = article.find('div', class_='humble')\n",
    "    date = date_tag.get_text(strip=True) if date_tag else 'No Date'\n",
    "    # Author\n",
    "    author_tag = article.find('a', class_='humble humble--author')\n",
    "    author = author_tag.get_text(strip=True) if author_tag else 'Unknown'\n",
    "    # Link\n",
    "    link_tag = article.find('a', class_='news__item-body')\n",
    "    link = link_tag['href'] if link_tag and link_tag.has_attr('href') else 'No Link'\n",
    "\n",
    "    # Use (title, date, author, link) as a unique identifier\n",
    "    identifier = (title, date, author, link)\n",
    "    if identifier not in seen:\n",
    "        data.append({\n",
    "            'Title': title,\n",
    "            'Date': date,\n",
    "            'Author': author,\n",
    "            'Link': link\n",
    "        })\n",
    "        seen.add(identifier)\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1018c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from df into PostgreSQL database\n",
    "def insert_news_data_pg(title, date, author, link):\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        INSERT INTO news (Title, Date, Author, Link)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "        ON CONFLICT (Title, Date) DO NOTHING\n",
    "    ''', (title, date, author, link))\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "# Create the news table if it doesn't exist\n",
    "def create_news_table():\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS news (\n",
    "            Title TEXT,\n",
    "            Date TEXT,\n",
    "            Author TEXT,\n",
    "            Link TEXT,\n",
    "            PRIMARY KEY (Title, Date)\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "create_news_table()\n",
    "# Insert the data into the database\n",
    "for index, row in df.iterrows():\n",
    "    insert_news_data_pg(row['Title'], row['Date'], row['Author'], row['Link'])\n",
    "# Function to query the news data from PostgreSQL\n",
    "def query_news_data_pg():\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT * FROM news ORDER BY Date DESC LIMIT 5')\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return rows\n",
    "# Print the last 5 news entries from the database\n",
    "last_news_entries = query_news_data_pg()\n",
    "for entry in last_news_entries:\n",
    "    print(f\"Title: {entry[0]}, Date: {entry[1]}, Author: {entry[2]}, Link: {entry[3]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249510bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Hello World\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
